{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oojEjJ8vOGCm",
        "outputId": "e1f13585-8a9e-44e8-81d1-0f42d5693d61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/OpenAi/Scanner\n",
            "Cloning into 'Quickly_Extract_Science_Papers'...\n",
            "remote: Enumerating objects: 65, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 65 (delta 9), reused 6 (delta 6), pack-reused 53\u001b[K\n",
            "Receiving objects: 100% (65/65), 29.73 MiB | 18.85 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/OpenAi/Scanner\n",
        "!git clone https://github.com/daveshap/Quickly_Extract_Science_Papers.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/OpenAi/Scanner/Quickly_Extract_Science_Papers\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "ohu8anrnOzfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Chat.py\n",
        "import openai\n",
        "from time import time, sleep\n",
        "from halo import Halo\n",
        "import textwrap\n",
        "import yaml\n",
        "\n",
        "\n",
        "###     file operations\n",
        "\n",
        "\n",
        "def save_file(filepath, content):\n",
        "    with open(filepath, 'w', encoding='utf-8') as outfile:\n",
        "        outfile.write(content)\n",
        "\n",
        "\n",
        "\n",
        "def open_file(filepath):\n",
        "    with open(filepath, 'r', encoding='utf-8', errors='ignore') as infile:\n",
        "        return infile.read()\n",
        "\n",
        "\n",
        "def save_yaml(filepath, data):\n",
        "    with open(filepath, 'w', encoding='utf-8') as file:\n",
        "        yaml.dump(data, file, allow_unicode=True)\n",
        "\n",
        "\n",
        "def open_yaml(filepath):\n",
        "    with open(filepath, 'r', encoding='utf-8') as file:\n",
        "        data = yaml.load(file, Loader=yaml.FullLoader)\n",
        "    return data\n",
        "\n",
        "\n",
        "###     API functions\n",
        "\n",
        "\n",
        "def chatbot(conversation, model=\"gpt-3.5-turbo-16k-0613\", temperature=0):#gpt-4-0613\n",
        "    max_retry = 7\n",
        "    retry = 0\n",
        "    while True:\n",
        "        try:\n",
        "            spinner = Halo(text='Thinking...', spinner='dots')\n",
        "            spinner.start()\n",
        "\n",
        "            response = openai.ChatCompletion.create(model=model, messages=conversation, temperature=temperature)\n",
        "            text = response['choices'][0]['message']['content']\n",
        "\n",
        "            spinner.stop()\n",
        "\n",
        "            return text, response['usage']['total_tokens']\n",
        "        except Exception as oops:\n",
        "            print(f'\\n\\nError communicating with OpenAI: \"{oops}\"')\n",
        "            if 'maximum context length' in str(oops):\n",
        "                a = conversation.pop(0)\n",
        "                print('\\n\\n DEBUG: Trimming oldest message')\n",
        "                continue\n",
        "            retry += 1\n",
        "            if retry >= max_retry:\n",
        "                print(f\"\\n\\nExiting due to excessive errors in API: {oops}\")\n",
        "                exit(1)\n",
        "            print(f'\\n\\nRetrying in {2 ** (retry - 1) * 5} seconds...')\n",
        "            sleep(2 ** (retry - 1) * 5)\n",
        "\n",
        "\n",
        "def chat_print(text):\n",
        "    formatted_lines = [textwrap.fill(line, width=120, initial_indent='    ', subsequent_indent='    ') for line in text.split('\\n')]\n",
        "    formatted_text = '\\n'.join(formatted_lines)\n",
        "    print('\\n\\n\\nCHATBOT:\\n\\n%s' % formatted_text)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    openai.api_key = open_file('key_openai.txt').strip()\n",
        "    paper = open_file('input.txt')\n",
        "    if len(paper) > 22000:\n",
        "        paper = paper[0:22000]\n",
        "    ALL_MESSAGES = [{'role':'system', 'content': paper}]\n",
        "    while True:\n",
        "        # get user input\n",
        "        text = input('\\n\\n\\nUSER:\\n\\n')\n",
        "        if text == '':\n",
        "            # empty submission, probably on accident\n",
        "            continue\n",
        "        ALL_MESSAGES.append({'role': 'user', 'content': text})\n",
        "\n",
        "        # get response\n",
        "        response, tokens = chatbot(ALL_MESSAGES)\n",
        "        if tokens >= 7800:\n",
        "            a = ALL_MESSAGES.pop(1)\n",
        "        chat_print(response)\n",
        "        ALL_MESSAGES.append({'role': 'assistant', 'content': response})"
      ],
      "metadata": {
        "id": "tXU9Gn0oP0Kw",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate multiple reports\n",
        "import openai\n",
        "from time import time, sleep\n",
        "from halo import Halo\n",
        "import textwrap\n",
        "import yaml\n",
        "import os\n",
        "import PyPDF2\n",
        "\n",
        "\n",
        "prompts = [\n",
        "'Can you give me a very clear explanation of the core assertions, implications, and mechanics elucidated in this paper?',\n",
        "\n",
        "\"Can you explain the value of this in basic terms? Like you're talking to a CEO. So what? What's the bottom line here?\",\n",
        "\n",
        "'Can you give me an analogy or metaphor that will help explain this to a broad audience.',\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "###     file operations\n",
        "\n",
        "\n",
        "def save_file(filepath, content):\n",
        "    with open(filepath, 'w', encoding='utf-8') as outfile:\n",
        "        outfile.write(content)\n",
        "\n",
        "\n",
        "\n",
        "def open_file(filepath):\n",
        "    with open(filepath, 'r', encoding='utf-8', errors='ignore') as infile:\n",
        "        return infile.read()\n",
        "\n",
        "\n",
        "def save_yaml(filepath, data):\n",
        "    with open(filepath, 'w', encoding='utf-8') as file:\n",
        "        yaml.dump(data, file, allow_unicode=True)\n",
        "\n",
        "\n",
        "def open_yaml(filepath):\n",
        "    with open(filepath, 'r', encoding='utf-8') as file:\n",
        "        data = yaml.load(file, Loader=yaml.FullLoader)\n",
        "    return data\n",
        "\n",
        "\n",
        "###     API functions\n",
        "\n",
        "\n",
        "def chatbot(conversation, model=\"gpt-3.5-turbo-16k-0613\", temperature=0):\n",
        "    max_retry = 7\n",
        "    retry = 0\n",
        "    while True:\n",
        "        try:\n",
        "            spinner = Halo(text='Thinking...', spinner='dots')\n",
        "            spinner.start()\n",
        "\n",
        "            response = openai.ChatCompletion.create(model=model, messages=conversation, temperature=temperature)\n",
        "            text = response['choices'][0]['message']['content']\n",
        "\n",
        "            spinner.stop()\n",
        "\n",
        "            return text, response['usage']['total_tokens']\n",
        "        except Exception as oops:\n",
        "            print(f'\\n\\nError communicating with OpenAI: \"{oops}\"')\n",
        "            if 'maximum context length' in str(oops):\n",
        "                a = conversation.pop(0)\n",
        "                print('\\n\\n DEBUG: Trimming oldest message')\n",
        "                continue\n",
        "            retry += 1\n",
        "            if retry >= max_retry:\n",
        "                print(f\"\\n\\nExiting due to excessive errors in API: {oops}\")\n",
        "                exit(1)\n",
        "            print(f'\\n\\nRetrying in {2 ** (retry - 1) * 5} seconds...')\n",
        "            sleep(2 ** (retry - 1) * 5)\n",
        "\n",
        "\n",
        "\n",
        "def chat_print(text):\n",
        "    formatted_lines = [textwrap.fill(line, width=120, initial_indent='    ', subsequent_indent='    ') for line in text.split('\\n')]\n",
        "    formatted_text = '\\n'.join(formatted_lines)\n",
        "    print('\\n\\n\\nCHATBOT:\\n\\n%s' % formatted_text)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # instantiate chatbot, variables\n",
        "    openai.api_key = open_file('key_openai.txt').strip()\n",
        "\n",
        "    # Get list of all PDF files in the input folder\n",
        "    pdf_files = [f for f in os.listdir('input/') if f.endswith('.pdf')]\n",
        "\n",
        "    for pdf_file in pdf_files:\n",
        "        # Check if the report already exists in the output folder\n",
        "        filename = 'output/' + pdf_file.replace('.pdf', '.txt')\n",
        "        if os.path.exists(filename):\n",
        "            continue\n",
        "\n",
        "        # Open the PDF file\n",
        "        with open('input/' + pdf_file, 'rb') as file:\n",
        "            pdf_reader = PyPDF2.PdfReader(file)\n",
        "            paper = ''\n",
        "            for page_num in list(range(0,len(pdf_reader.pages))):\n",
        "                page = pdf_reader.pages[page_num]\n",
        "                paper += page.extract_text()\n",
        "\n",
        "        if len(paper) > 22000:\n",
        "            paper = paper[0:22000]\n",
        "        ALL_MESSAGES = [{'role':'system', 'content': paper}]\n",
        "        report = ''\n",
        "        for p in prompts:\n",
        "            ALL_MESSAGES.append({'role':'user', 'content': p})\n",
        "            response, tokens = chatbot(ALL_MESSAGES)\n",
        "            chat_print(response)\n",
        "            ALL_MESSAGES.append({'role':'assistant', 'content': response})\n",
        "            report += '\\n\\n\\n\\nQ: %s\\n\\nA: %s' % (p, response)\n",
        "\n",
        "        # Save the report in the output folder with the same name as the PDF file but with .txt extension\n",
        "        save_file(filename, report.strip())"
      ],
      "metadata": {
        "id": "NjLTDZ8FkCOk",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Repo Contents\n",
        "chat.py - this file is a simple chatbot that will chat with you about the contents of input.txt (you can copy/paste anything into this text file). Very useful to quickly discuss papers.\n",
        "generate_multiple_reports.py - this will consume all PDFs in the input/ folder and generate summaries in the output/ folder. This is helpful for bulk processing such as for literature reviews.\n",
        "render_report.py - this will render all the reports in output/ to a an easier to read file in report.html.\n",
        "EXECUTIVE SUMMARY\n",
        "This repository contains Python scripts that automate the process of generating reports from PDF files using OpenAI's GPT-4 model. The scripts extract text from PDF files, send the text to the GPT-4 model for processing, and save the generated reports as text files. The scripts also include functionality to render the generated reports as an HTML document for easy viewing.\n",
        "\n",
        "SETUP\n",
        "Clone the repository to your local machine.\n",
        "Install the required Python packages by running pip install -r requirements.txt in your terminal.\n",
        "Obtain an API key from OpenAI and save it in a file named key_openai.txt in the root directory of the repository.\n",
        "Place the PDF files you want to generate reports from in the input/ directory.\n",
        "USAGE\n",
        "Run the generate_multiple_reports.py script to generate reports from the PDF files in the input/ directory. The generated reports will be saved as text files in the output/ directory.\n",
        "Run the render_report.py script to render the generated reports as an HTML document. The HTML document will be saved as report.html in the root directory of the repository.\n",
        "You can modify the prompts in generate_multiple_reports.py to focus on any questions you would like to ask. In other words you can automatically ask any set of questions in bulk against any set of papers. This can help you greatly accelerate your literature reviews and surveys.\n",
        "NOTE\n",
        "The scripts are designed to handle errors and retries when communicating with the OpenAI API. If the API returns an error due to the maximum context length being exceeded, the scripts will automatically trim the oldest message and retry the API call. If the API returns any other type of error, the scripts will retry the API call after a delay, with the delay increasing exponentially for each consecutive error. If the API returns errors for seven consecutive attempts, the scripts will stop and exit.'''"
      ],
      "metadata": {
        "id": "jbCqF8O6PvbK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}